# Worker Threads å¹¶è¡Œå¤„ç†å®æ–½æŒ‡å—

## æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾› Worker Threads å¹¶è¡Œå¤„ç†ä¼˜åŒ–çš„è¯¦ç»†å®æ–½æŒ‡å—ï¼ŒåŒ…æ‹¬å…³é”®å®ç°ç»†èŠ‚ã€ä¼˜åŒ–å»ºè®®å’Œæœ€ä½³å®è·µã€‚

## ç›®æ ‡

- **æ€§èƒ½ç›®æ ‡ï¼š** å°† 100 ä¸‡è¡Œæ•°æ®å¤„ç†æ—¶é—´ä» 150-240 ç§’é™ä½åˆ° 45-60 ç§’
- **åŠ é€Ÿæ¯”ï¼š** è‡³å°‘ 250% æ€§èƒ½æå‡ï¼ˆ2.5x åŠ é€Ÿï¼‰
- **èµ„æºåˆ©ç”¨ï¼š** CPU åˆ©ç”¨ç‡ä» 25% æå‡åˆ° 80-100%
- **æ•°æ®å®Œæ•´æ€§ï¼š** ä¿æŒ 100% æ•°æ®å‡†ç¡®æ€§

## æ ¸å¿ƒæ¶æ„

### 1. ä¸»çº¿ç¨‹èŒè´£

ä¸»çº¿ç¨‹ä½œä¸ºåè°ƒå™¨ï¼Œè´Ÿè´£ï¼š
- è¯»å–é…ç½®å¹¶å†³å®šæ˜¯å¦ä½¿ç”¨å¹¶è¡Œå¤„ç†
- è®¡ç®— CSV æ–‡ä»¶æ€»è¡Œæ•°
- å°†æ–‡ä»¶åˆ†å‰²æˆå‡è¡¡çš„æ•°æ®å—
- åˆ›å»ºå’Œç®¡ç†å·¥ä½œçº¿ç¨‹æ± 
- æ”¶é›†å’Œèšåˆå·¥ä½œçº¿ç¨‹ç»“æœ
- è·Ÿè¸ªæ•´ä½“è¿›åº¦
- å¤„ç†é”™è¯¯å’Œè¶…æ—¶

### 2. å·¥ä½œçº¿ç¨‹èŒè´£

æ¯ä¸ªå·¥ä½œçº¿ç¨‹ç‹¬ç«‹è´Ÿè´£ï¼š
- è¯»å–åˆ†é…çš„ CSV è¡ŒèŒƒå›´
- åº”ç”¨æ•°æ®éªŒè¯è§„åˆ™
- æ‰¹é‡æ’å…¥æ¸…æ´—æ•°æ®åˆ°æ•°æ®åº“
- è®°å½•é”™è¯¯åˆ°é”™è¯¯æ—¥å¿—
- å®šæœŸæŠ¥å‘Šè¿›åº¦
- ç®¡ç†è‡ªèº«å†…å­˜ä½¿ç”¨


## å…³é”®å®ç°ç»†èŠ‚

### 1. CSV æ–‡ä»¶åˆ†å—ç­–ç•¥

**æŒ‘æˆ˜ï¼š** å¦‚ä½•é«˜æ•ˆåœ°å°†å¤§å‹ CSV æ–‡ä»¶åˆ†å‰²ç»™å¤šä¸ªå·¥ä½œçº¿ç¨‹ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š** ä½¿ç”¨è¡Œç´¢å¼•èŒƒå›´åˆ†é…

```typescript
// ç¤ºä¾‹ï¼š100 ä¸‡è¡Œåˆ†é…ç»™ 4 ä¸ªå·¥ä½œçº¿ç¨‹
// Worker 1: è¡Œ 0-249,999
// Worker 2: è¡Œ 250,000-499,999
// Worker 3: è¡Œ 500,000-749,999
// Worker 4: è¡Œ 750,000-999,999

function calculateChunks(totalRows: number, workerCount: number): ChunkDescriptor[] {
  const baseChunkSize = Math.floor(totalRows / workerCount);
  const remainder = totalRows % workerCount;
  
  const chunks: ChunkDescriptor[] = [];
  let startRow = 0;
  
  for (let i = 0; i < workerCount; i++) {
    // å°†ä½™æ•°åˆ†é…ç»™å‰å‡ ä¸ªå·¥ä½œçº¿ç¨‹
    const chunkSize = baseChunkSize + (i < remainder ? 1 : 0);
    chunks.push({
      chunkId: i,
      startRow,
      endRow: startRow + chunkSize,
      rowCount: chunkSize,
    });
    startRow += chunkSize;
  }
  
  return chunks;
}
```

**ä¼˜åŒ–å»ºè®®ï¼š**
- ç¡®ä¿æ•°æ®å—å¤§å°å·®å¼‚ä¸è¶…è¿‡ 1 è¡Œ
- å¯¹äºå°æ–‡ä»¶ï¼ˆ< 1000 è¡Œï¼‰ï¼Œä½¿ç”¨é¡ºåºå¤„ç†
- è€ƒè™‘æ–‡ä»¶å¤§å°å’Œå¯ç”¨å†…å­˜åŠ¨æ€è°ƒæ•´å·¥ä½œçº¿ç¨‹æ•°


### 2. å·¥ä½œçº¿ç¨‹ CSV è¯»å–ä¼˜åŒ–

**æŒ‘æˆ˜ï¼š** æ¯ä¸ªå·¥ä½œçº¿ç¨‹å¦‚ä½•é«˜æ•ˆè¯»å–å…¶åˆ†é…çš„è¡ŒèŒƒå›´ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š** ä½¿ç”¨æµå¼è¯»å– + è¡Œè·³è¿‡

```typescript
// åœ¨ data-cleaning.worker.ts ä¸­
import * as fs from 'fs';
import * as readline from 'readline';

async function readCsvChunk(
  filePath: string,
  startRow: number,
  rowCount: number
): Promise<string[][]> {
  const rows: string[][] = [];
  let currentRow = 0;
  
  const fileStream = fs.createReadStream(filePath);
  const rl = readline.createInterface({
    input: fileStream,
    crlfDelay: Infinity
  });
  
  for await (const line of rl) {
    // è·³è¿‡æ ‡é¢˜è¡Œ
    if (currentRow === 0) {
      currentRow++;
      continue;
    }
    
    // è·³è¿‡ä¸å±äºæ­¤å·¥ä½œçº¿ç¨‹çš„è¡Œ
    if (currentRow - 1 < startRow) {
      currentRow++;
      continue;
    }
    
    // è¯»å–åˆ†é…çš„è¡Œ
    if (currentRow - 1 < startRow + rowCount) {
      rows.push(parseCsvLine(line));
      currentRow++;
    } else {
      // å·²è¯»å–å®Œæ‰€æœ‰åˆ†é…çš„è¡Œ
      break;
    }
  }
  
  return rows;
}
```

**ä¼˜åŒ–å»ºè®®ï¼š**
- ä½¿ç”¨ `readline` æ¨¡å—è¿›è¡Œæµå¼è¯»å–ï¼Œé¿å…å†…å­˜æº¢å‡º
- å®ç°é«˜æ•ˆçš„è¡Œè·³è¿‡é€»è¾‘
- è€ƒè™‘ä½¿ç”¨æ›´å¿«çš„ CSV è§£æåº“ï¼ˆå¦‚ `csv-parser`, `papaparse`ï¼‰
- å¯¹äºå¤§æ–‡ä»¶ï¼Œè€ƒè™‘ä½¿ç”¨æ–‡ä»¶åç§»é‡ç›´æ¥å®šä½


### 3. æ‰¹é‡æ•°æ®åº“æ’å…¥ä¼˜åŒ–

**æŒ‘æˆ˜ï¼š** å¦‚ä½•æœ€å¤§åŒ–æ•°æ®åº“æ’å…¥æ€§èƒ½ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š** ä½¿ç”¨å¤§æ‰¹æ¬¡ + åŸç”Ÿ SQL + äº‹åŠ¡

```typescript
// åœ¨ worker ä¸­å®ç°é«˜æ€§èƒ½æ‰¹é‡æ’å…¥
async function batchInsertCleanData(
  records: CleanDataRecord[],
  batchSize: number = 10000
): Promise<void> {
  const queryRunner = dataSource.createQueryRunner();
  await queryRunner.connect();
  
  try {
    await queryRunner.startTransaction();
    
    // åˆ†æ‰¹æ’å…¥
    for (let i = 0; i < records.length; i += batchSize) {
      const batch = records.slice(i, i + batchSize);
      
      // ä½¿ç”¨åŸç”Ÿ SQL æ‰¹é‡æ’å…¥ï¼ˆæ¯” TypeORM save() å¿« 3-5 å€ï¼‰
      const values = batch.map(r => 
        `(${queryRunner.escape(r.jobId)}, ${r.rowNumber}, ` +
        `${queryRunner.escape(r.name)}, ${queryRunner.escape(r.phone)}, ` +
        `${queryRunner.escape(r.address)}, ${queryRunner.escape(r.date)})`
      ).join(',');
      
      await queryRunner.query(
        `INSERT INTO clean_data (jobId, rowNumber, name, phone, address, date) ` +
        `VALUES ${values}`
      );
    }
    
    await queryRunner.commitTransaction();
  } catch (error) {
    await queryRunner.rollbackTransaction();
    throw error;
  } finally {
    await queryRunner.release();
  }
}
```

**ä¼˜åŒ–å»ºè®®ï¼š**
- ä½¿ç”¨æ‰¹æ¬¡å¤§å° 10000ï¼ˆå¹³è¡¡å†…å­˜å’Œæ€§èƒ½ï¼‰
- ä½¿ç”¨åŸç”Ÿ SQL è€Œé ORM æ–¹æ³•
- ä½¿ç”¨äº‹åŠ¡å‡å°‘æäº¤å¼€é”€
- è€ƒè™‘åœ¨æ’å…¥æœŸé—´ç¦ç”¨ç´¢å¼•ï¼ˆéœ€è¦æƒé™ï¼‰
- å¢åŠ æ•°æ®åº“è¿æ¥æ± å¤§å°ï¼ˆè‡³å°‘ 20 ä¸ªè¿æ¥ï¼‰


### 4. å·¥ä½œçº¿ç¨‹é€šä¿¡æ¨¡å¼

**æŒ‘æˆ˜ï¼š** å¦‚ä½•åœ¨ä¸»çº¿ç¨‹å’Œå·¥ä½œçº¿ç¨‹ä¹‹é—´é«˜æ•ˆé€šä¿¡ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š** ä½¿ç”¨ç»“æ„åŒ–æ¶ˆæ¯ä¼ é€’

```typescript
// ä¸»çº¿ç¨‹å‘é€ä»»åŠ¡åˆ°å·¥ä½œçº¿ç¨‹
const worker = new Worker('./data-cleaning.worker.js');

worker.postMessage({
  type: 'START',
  payload: {
    filePath: '/path/to/file.csv',
    startRow: 0,
    rowCount: 250000,
    batchSize: 10000,
    workerId: 1,
    dbConfig: {
      host: process.env.DB_HOST,
      port: process.env.DB_PORT,
      // ...
    }
  }
});

// å·¥ä½œçº¿ç¨‹ç›‘å¬æ¶ˆæ¯
parentPort.on('message', async (message) => {
  if (message.type === 'START') {
    const { filePath, startRow, rowCount, batchSize, workerId } = message.payload;
    
    try {
      // å¤„ç†æ•°æ®
      const result = await processChunk(filePath, startRow, rowCount, batchSize);
      
      // å‘é€å®Œæˆæ¶ˆæ¯
      parentPort.postMessage({
        type: 'COMPLETE',
        payload: {
          workerId,
          successCount: result.successCount,
          errorCount: result.errorCount,
          processingTimeMs: result.timeMs
        }
      });
    } catch (error) {
      // å‘é€é”™è¯¯æ¶ˆæ¯
      parentPort.postMessage({
        type: 'ERROR',
        payload: {
          workerId,
          error: error.message,
          stack: error.stack
        }
      });
    }
  }
});

// å·¥ä½œçº¿ç¨‹å®šæœŸå‘é€è¿›åº¦æ›´æ–°
function reportProgress(workerId: number, processed: number, total: number) {
  parentPort.postMessage({
    type: 'PROGRESS',
    payload: {
      workerId,
      processedRows: processed,
      totalRows: total,
      percentage: (processed / total) * 100
    }
  });
}
```

**ä¼˜åŒ–å»ºè®®ï¼š**
- ä½¿ç”¨ç±»å‹åŒ–æ¶ˆæ¯æ¥å£
- é™åˆ¶è¿›åº¦æ›´æ–°é¢‘ç‡ï¼ˆå¦‚æ¯ 1000 è¡Œæˆ–æ¯ç§’ï¼‰
- é¿å…ä¼ é€’å¤§å¯¹è±¡ï¼ˆä½¿ç”¨ SharedArrayBuffer å¦‚éœ€è¦ï¼‰
- å®ç°è¶…æ—¶æœºåˆ¶é˜²æ­¢å·¥ä½œçº¿ç¨‹æŒ‚èµ·


### 5. é”™è¯¯å¤„ç†å’Œæ¢å¤

**æŒ‘æˆ˜ï¼š** å¦‚ä½•å¤„ç†å·¥ä½œçº¿ç¨‹å´©æºƒå’Œé”™è¯¯ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š** å¤šå±‚é”™è¯¯å¤„ç† + éƒ¨åˆ†ç»“æœæ”¶é›†

```typescript
// åœ¨ ParallelProcessingManager ä¸­
async processFile(filePath: string, config: ProcessingConfig): Promise<ProcessingResult> {
  const chunks = await this.chunkSplitter.splitFile(filePath, config.workerCount);
  const workerPromises: Promise<WorkerResult>[] = [];
  
  for (const chunk of chunks) {
    const workerPromise = this.executeWorkerWithTimeout(chunk, config.timeoutMs)
      .catch(error => {
        // å·¥ä½œçº¿ç¨‹å¤±è´¥ï¼Œè¿”å›é”™è¯¯ç»“æœ
        this.logger.error(`Worker ${chunk.chunkId} failed: ${error.message}`);
        return {
          workerId: chunk.chunkId,
          successCount: 0,
          errorCount: 0,
          processingTimeMs: 0,
          errors: [{ message: error.message, stack: error.stack }]
        };
      });
    
    workerPromises.push(workerPromise);
  }
  
  // ç­‰å¾…æ‰€æœ‰å·¥ä½œçº¿ç¨‹å®Œæˆï¼ˆåŒ…æ‹¬å¤±è´¥çš„ï¼‰
  const results = await Promise.all(workerPromises);
  
  // èšåˆç»“æœï¼ˆåŒ…æ‹¬éƒ¨åˆ†ç»“æœï¼‰
  return this.resultCollector.aggregateResults(results);
}

// å®ç°è¶…æ—¶æœºåˆ¶
private executeWorkerWithTimeout(
  chunk: ChunkDescriptor,
  timeoutMs: number
): Promise<WorkerResult> {
  return new Promise((resolve, reject) => {
    const worker = new Worker('./data-cleaning.worker.js');
    
    // è®¾ç½®è¶…æ—¶
    const timeout = setTimeout(() => {
      worker.terminate();
      reject(new Error(`Worker ${chunk.chunkId} timed out after ${timeoutMs}ms`));
    }, timeoutMs);
    
    worker.on('message', (message) => {
      if (message.type === 'COMPLETE') {
        clearTimeout(timeout);
        worker.terminate();
        resolve(message.payload);
      } else if (message.type === 'ERROR') {
        clearTimeout(timeout);
        worker.terminate();
        reject(new Error(message.payload.error));
      }
    });
    
    worker.on('error', (error) => {
      clearTimeout(timeout);
      worker.terminate();
      reject(error);
    });
    
    // å‘é€ä»»åŠ¡
    worker.postMessage({ type: 'START', payload: chunk });
  });
}
```

**ä¼˜åŒ–å»ºè®®ï¼š**
- å®ç°å·¥ä½œçº¿ç¨‹è¶…æ—¶ï¼ˆé»˜è®¤ 5 åˆ†é’Ÿï¼‰
- æ•è·æ‰€æœ‰å·¥ä½œçº¿ç¨‹é”™è¯¯å¹¶è®°å½•
- å³ä½¿éƒ¨åˆ†å·¥ä½œçº¿ç¨‹å¤±è´¥ä¹Ÿè¿”å›ç»“æœ
- åœ¨å·¥ä½œçº¿ç¨‹ä¸­å®ç°å…¨å±€é”™è¯¯å¤„ç†
- è€ƒè™‘å®ç°é‡è¯•æœºåˆ¶ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰


## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®åº“å±‚ä¼˜åŒ–

**è¿æ¥æ± é…ç½®ï¼š**
```typescript
// åœ¨ TypeORM é…ç½®ä¸­
{
  type: 'mysql',
  host: process.env.DB_HOST,
  port: parseInt(process.env.DB_PORT),
  // å¢åŠ è¿æ¥æ± å¤§å°ä»¥æ”¯æŒå¹¶è¡Œå·¥ä½œçº¿ç¨‹
  extra: {
    connectionLimit: 20,  // è‡³å°‘ 4 ä¸ªå·¥ä½œçº¿ç¨‹ * 4 + ä¸»çº¿ç¨‹
    waitForConnections: true,
    queueLimit: 0
  }
}
```

**MySQL é…ç½®ä¼˜åŒ–ï¼š**
```ini
# my.cnf æˆ– my.ini
[mysqld]
# å¢åŠ ç¼“å†²æ± å¤§å°
innodb_buffer_pool_size = 2G

# å¢åŠ æ—¥å¿—æ–‡ä»¶å¤§å°
innodb_log_file_size = 512M

# è°ƒæ•´åˆ·æ–°ç­–ç•¥ï¼ˆç‰ºç‰²ä¸€äº›æŒä¹…æ€§æ¢å–æ€§èƒ½ï¼‰
innodb_flush_log_at_trx_commit = 2

# å¢åŠ æ‰¹é‡æ’å…¥ç¼“å†²åŒº
bulk_insert_buffer_size = 256M

# å¢åŠ æœ€å¤§åŒ…å¤§å°
max_allowed_packet = 256M

# ç¦ç”¨æŸ¥è¯¢ç¼“å­˜ï¼ˆMySQL 8.0 å·²ç§»é™¤ï¼‰
# query_cache_type = 0
```

**ç´¢å¼•ä¼˜åŒ–ï¼š**
```sql
-- åœ¨å¤„ç†å‰ç¦ç”¨ç´¢å¼•ï¼ˆéœ€è¦ ALTER æƒé™ï¼‰
ALTER TABLE clean_data DISABLE KEYS;
ALTER TABLE error_log DISABLE KEYS;

-- æ‰¹é‡æ’å…¥æ•°æ®...

-- å¤„ç†åé‡å»ºç´¢å¼•
ALTER TABLE clean_data ENABLE KEYS;
ALTER TABLE error_log ENABLE KEYS;
```


### 2. CSV è§£æä¼˜åŒ–

**ä½¿ç”¨é«˜æ€§èƒ½ CSV è§£æåº“ï¼š**

```bash
# å®‰è£… csv-parserï¼ˆæ¯”æ‰‹åŠ¨è§£æå¿« 2-3 å€ï¼‰
npm install csv-parser
```

```typescript
import csv from 'csv-parser';
import * as fs from 'fs';

async function readCsvChunkOptimized(
  filePath: string,
  startRow: number,
  rowCount: number
): Promise<any[]> {
  return new Promise((resolve, reject) => {
    const rows: any[] = [];
    let currentRow = 0;
    
    fs.createReadStream(filePath)
      .pipe(csv())
      .on('data', (row) => {
        if (currentRow >= startRow && currentRow < startRow + rowCount) {
          rows.push(row);
        }
        currentRow++;
        
        // æå‰ç»ˆæ­¢æµ
        if (currentRow >= startRow + rowCount) {
          this.destroy();
        }
      })
      .on('end', () => resolve(rows))
      .on('error', reject);
  });
}
```

**é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼š**
```typescript
// åœ¨ Worker åˆå§‹åŒ–æ—¶é¢„ç¼–è¯‘
class DataValidator {
  private readonly phoneRegex = /^1[3-9]\d{9}$/;
  private readonly dateRegex = /^\d{4}[-/.å¹´]\d{1,2}[-/.æœˆ]?\d{1,2}æ—¥?$/;
  private readonly addressRegex = /^[\u4e00-\u9fa5a-zA-Z0-9\s,ï¼Œ.ã€‚-]+$/;
  
  validatePhone(phone: string): boolean {
    return this.phoneRegex.test(phone);
  }
  
  validateDate(date: string): boolean {
    return this.dateRegex.test(date);
  }
  
  validateAddress(address: string): boolean {
    return this.addressRegex.test(address);
  }
}
```


### 3. å†…å­˜ç®¡ç†ä¼˜åŒ–

**æµå¼å¤„ç†é¿å…å†…å­˜æº¢å‡ºï¼š**
```typescript
async function processChunkStreaming(
  filePath: string,
  startRow: number,
  rowCount: number,
  batchSize: number
): Promise<WorkerResult> {
  let successCount = 0;
  let errorCount = 0;
  let currentBatch: CleanDataRecord[] = [];
  let processedRows = 0;
  
  const stream = fs.createReadStream(filePath)
    .pipe(csv());
  
  for await (const row of stream) {
    if (processedRows >= startRow && processedRows < startRow + rowCount) {
      const validationResult = validateRow(row);
      
      if (validationResult.isValid) {
        currentBatch.push(validationResult.cleanData);
        
        // è¾¾åˆ°æ‰¹æ¬¡å¤§å°ï¼Œç«‹å³æ’å…¥å¹¶æ¸…ç©º
        if (currentBatch.length >= batchSize) {
          await batchInsertCleanData(currentBatch);
          successCount += currentBatch.length;
          currentBatch = [];  // é‡Šæ”¾å†…å­˜
        }
      } else {
        await logError(validationResult.error);
        errorCount++;
      }
    }
    
    processedRows++;
    
    // æå‰ç»ˆæ­¢
    if (processedRows >= startRow + rowCount) {
      break;
    }
  }
  
  // æ’å…¥å‰©ä½™è®°å½•
  if (currentBatch.length > 0) {
    await batchInsertCleanData(currentBatch);
    successCount += currentBatch.length;
  }
  
  return { successCount, errorCount };
}
```

**ç›‘æ§å†…å­˜ä½¿ç”¨ï¼š**
```typescript
function checkMemoryUsage(): void {
  const usage = process.memoryUsage();
  const usedMB = usage.heapUsed / 1024 / 1024;
  
  if (usedMB > 1800) {
    console.warn(`High memory usage: ${usedMB.toFixed(2)} MB`);
    // è§¦å‘åƒåœ¾å›æ”¶ï¼ˆéœ€è¦ --expose-gc æ ‡å¿—ï¼‰
    if (global.gc) {
      global.gc();
    }
  }
}
```


### 4. åŠ¨æ€å·¥ä½œçº¿ç¨‹æ•°è°ƒæ•´

**æ ¹æ®ç³»ç»Ÿèµ„æºåŠ¨æ€è°ƒæ•´ï¼š**
```typescript
import * as os from 'os';

function calculateOptimalWorkerCount(): number {
  const cpuCount = os.cpus().length;
  const totalMemoryGB = os.totalmem() / (1024 ** 3);
  
  // åŸºäº CPU æ ¸å¿ƒæ•°ï¼ˆä¿ç•™ 1 ä¸ªæ ¸å¿ƒç»™ä¸»çº¿ç¨‹ï¼‰
  const cpuBasedCount = Math.max(1, cpuCount - 1);
  
  // åŸºäºå†…å­˜ï¼ˆæ¯ä¸ªå·¥ä½œçº¿ç¨‹å‡è®¾éœ€è¦ 500MBï¼‰
  const memoryBasedCount = Math.floor(totalMemoryGB * 0.8 / 0.5);
  
  // å–è¾ƒå°å€¼ï¼Œæœ€å¤š 8 ä¸ªå·¥ä½œçº¿ç¨‹
  return Math.min(cpuBasedCount, memoryBasedCount, 8);
}

// åœ¨é…ç½®ä¸­ä½¿ç”¨
const workerCount = process.env.WORKER_COUNT 
  ? parseInt(process.env.WORKER_COUNT)
  : calculateOptimalWorkerCount();
```


## æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•ç¤ºä¾‹

```typescript
// chunk-splitter.service.spec.ts
describe('ChunkSplitter', () => {
  let splitter: ChunkSplitter;
  
  beforeEach(() => {
    splitter = new ChunkSplitter();
  });
  
  it('should split evenly divisible rows equally', () => {
    const chunks = splitter.calculateChunks(1000000, 4);
    
    expect(chunks).toHaveLength(4);
    expect(chunks[0].rowCount).toBe(250000);
    expect(chunks[1].rowCount).toBe(250000);
    expect(chunks[2].rowCount).toBe(250000);
    expect(chunks[3].rowCount).toBe(250000);
  });
  
  it('should distribute remainder rows', () => {
    const chunks = splitter.calculateChunks(1000001, 4);
    
    expect(chunks).toHaveLength(4);
    expect(chunks[0].rowCount).toBe(250001);  // è·å¾—ä½™æ•°
    expect(chunks[1].rowCount).toBe(250000);
    expect(chunks[2].rowCount).toBe(250000);
    expect(chunks[3].rowCount).toBe(250000);
  });
  
  it('should ensure max difference is 1', () => {
    const chunks = splitter.calculateChunks(999999, 4);
    const sizes = chunks.map(c => c.rowCount);
    const max = Math.max(...sizes);
    const min = Math.min(...sizes);
    
    expect(max - min).toBeLessThanOrEqual(1);
  });
});
```

### 2. å±æ€§æµ‹è¯•ç¤ºä¾‹

```typescript
// parallel-processing.property.spec.ts
import * as fc from 'fast-check';

describe('Parallel Processing Properties', () => {
  it('Property 1: Data integrity - total records preserved', async () => {
    await fc.assert(
      fc.asyncProperty(
        fc.integer({ min: 100, max: 10000 }),  // éšæœºè¡Œæ•°
        async (rowCount) => {
          // ç”Ÿæˆæµ‹è¯• CSV æ–‡ä»¶
          const filePath = await generateTestCsv(rowCount);
          
          // å¹¶è¡Œå¤„ç†
          const result = await parallelProcessor.processFile(filePath);
          
          // éªŒè¯ï¼šæˆåŠŸ + é”™è¯¯ = æ€»æ•°
          expect(result.successCount + result.errorCount).toBe(rowCount);
          
          // æ¸…ç†
          await fs.unlink(filePath);
        }
      ),
      { numRuns: 100 }  // è¿è¡Œ 100 æ¬¡
    );
  });
  
  it('Property 2: Chunk balance - max difference <= 1', () => {
    fc.assert(
      fc.property(
        fc.integer({ min: 1, max: 1000000 }),  // æ€»è¡Œæ•°
        fc.integer({ min: 1, max: 16 }),       // å·¥ä½œçº¿ç¨‹æ•°
        (totalRows, workerCount) => {
          const chunks = chunkSplitter.calculateChunks(totalRows, workerCount);
          const sizes = chunks.map(c => c.rowCount);
          const max = Math.max(...sizes);
          const min = Math.min(...sizes);
          
          return max - min <= 1;
        }
      ),
      { numRuns: 1000 }
    );
  });
  
  it('Property 3: Validation consistency', async () => {
    await fc.assert(
      fc.asyncProperty(
        fc.record({
          name: fc.string({ minLength: 1, maxLength: 50 }),
          phone: fc.string({ minLength: 11, maxLength: 11 }),
          address: fc.string({ minLength: 1, maxLength: 100 }),
          date: fc.string({ minLength: 8, maxLength: 20 })
        }),
        async (record) => {
          // å¹¶è¡ŒéªŒè¯
          const parallelResult = await validateInParallel(record);
          
          // é¡ºåºéªŒè¯
          const sequentialResult = await validateSequentially(record);
          
          // éªŒè¯ç»“æœåº”è¯¥ç›¸åŒ
          expect(parallelResult.isValid).toBe(sequentialResult.isValid);
          if (!parallelResult.isValid) {
            expect(parallelResult.errorMessage).toBe(sequentialResult.errorMessage);
          }
        }
      ),
      { numRuns: 500 }
    );
  });
});
```


### 3. æ€§èƒ½æµ‹è¯•è„šæœ¬

```typescript
// performance-test.ts
import * as fs from 'fs';
import * as path from 'path';

async function runPerformanceTest() {
  console.log('=== Performance Test: 1 Million Records ===\n');
  
  // 1. ç”Ÿæˆæµ‹è¯•æ•°æ®
  console.log('Generating test data...');
  const testFile = await generateLargeTestCsv(1000000);
  console.log(`Test file created: ${testFile}\n`);
  
  // 2. é¡ºåºå¤„ç†åŸºå‡†
  console.log('Running sequential processing...');
  const sequentialStart = Date.now();
  const sequentialResult = await processSequentially(testFile);
  const sequentialTime = Date.now() - sequentialStart;
  console.log(`Sequential: ${sequentialTime}ms`);
  console.log(`  Success: ${sequentialResult.successCount}`);
  console.log(`  Errors: ${sequentialResult.errorCount}\n`);
  
  // 3. å¹¶è¡Œå¤„ç†
  console.log('Running parallel processing...');
  const parallelStart = Date.now();
  const parallelResult = await processInParallel(testFile);
  const parallelTime = Date.now() - parallelStart;
  console.log(`Parallel: ${parallelTime}ms`);
  console.log(`  Success: ${parallelResult.successCount}`);
  console.log(`  Errors: ${parallelResult.errorCount}\n`);
  
  // 4. è®¡ç®—æ€§èƒ½æŒ‡æ ‡
  const speedup = sequentialTime / parallelTime;
  const throughput = 1000000 / (parallelTime / 1000);
  
  console.log('=== Performance Metrics ===');
  console.log(`Speedup: ${speedup.toFixed(2)}x`);
  console.log(`Throughput: ${throughput.toFixed(0)} rows/sec`);
  console.log(`Time saved: ${((sequentialTime - parallelTime) / 1000).toFixed(1)}s`);
  
  // 5. éªŒè¯ç›®æ ‡
  console.log('\n=== Target Validation ===');
  console.log(`âœ“ Processing time < 60s: ${parallelTime < 60000 ? 'PASS' : 'FAIL'}`);
  console.log(`âœ“ Speedup > 2x: ${speedup > 2 ? 'PASS' : 'FAIL'}`);
  console.log(`âœ“ Data integrity: ${
    sequentialResult.successCount === parallelResult.successCount ? 'PASS' : 'FAIL'
  }`);
  
  // 6. èµ„æºä½¿ç”¨
  const memUsage = process.memoryUsage();
  console.log('\n=== Resource Usage ===');
  console.log(`Memory: ${(memUsage.heapUsed / 1024 / 1024).toFixed(2)} MB`);
  console.log(`CPU cores: ${os.cpus().length}`);
  
  // æ¸…ç†
  await fs.promises.unlink(testFile);
}

// è¿è¡Œæµ‹è¯•
runPerformanceTest().catch(console.error);
```


## éƒ¨ç½²å’Œé…ç½®

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env æ–‡ä»¶
# å¹¶è¡Œå¤„ç†é…ç½®
ENABLE_PARALLEL_PROCESSING=true
WORKER_COUNT=4
PARALLEL_BATCH_SIZE=10000
MIN_RECORDS_FOR_PARALLEL=1000

# èµ„æºé™åˆ¶
MAX_MEMORY_MB=1800
WORKER_TIMEOUT_MS=300000

# è¿›åº¦è·Ÿè¸ª
ENABLE_PROGRESS_TRACKING=true
PROGRESS_UPDATE_INTERVAL=1000

# æ•°æ®åº“è¿æ¥æ± 
DB_CONNECTION_LIMIT=20
DB_QUEUE_LIMIT=0
```

### éƒ¨ç½²æ£€æŸ¥æ¸…å•

**éƒ¨ç½²å‰ï¼š**
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ˆå•å…ƒã€é›†æˆã€å±æ€§ã€æ€§èƒ½ï¼‰
- [ ] ä»£ç å®¡æŸ¥å®Œæˆ
- [ ] æ–‡æ¡£æ›´æ–°å®Œæˆ
- [ ] æ•°æ®åº“è¿æ¥æ± é…ç½®å·²æ›´æ–°
- [ ] ç¯å¢ƒå˜é‡å·²é…ç½®
- [ ] å›æ»šè®¡åˆ’å·²å‡†å¤‡

**éƒ¨ç½²æ­¥éª¤ï¼š**
1. å¤‡ä»½å½“å‰ä»£ç å’Œæ•°æ®åº“
2. éƒ¨ç½²æ–°ä»£ç åˆ°æµ‹è¯•ç¯å¢ƒ
3. è¿è¡Œå†’çƒŸæµ‹è¯•
4. è¿è¡Œæ€§èƒ½æµ‹è¯•éªŒè¯ç›®æ ‡
5. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
6. ç›‘æ§æ€§èƒ½æŒ‡æ ‡å’Œé”™è¯¯æ—¥å¿—
7. éªŒè¯åŠŸèƒ½æ­£å¸¸

**éƒ¨ç½²åç›‘æ§ï¼š**
- [ ] å¤„ç†æ—¶é—´æ˜¯å¦åœ¨é¢„æœŸèŒƒå›´å†…ï¼ˆ< 60 ç§’ï¼‰
- [ ] CPU åˆ©ç”¨ç‡æ˜¯å¦æå‡ï¼ˆ> 80%ï¼‰
- [ ] å†…å­˜ä½¿ç”¨æ˜¯å¦åœ¨é™åˆ¶å†…ï¼ˆ< 2GBï¼‰
- [ ] é”™è¯¯ç‡æ˜¯å¦æ­£å¸¸
- [ ] æ•°æ®å®Œæ•´æ€§æ˜¯å¦ä¿æŒ


## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

**é—®é¢˜ 1: æ€§èƒ½æœªè¾¾åˆ°é¢„æœŸ**

ç—‡çŠ¶ï¼šå¤„ç†æ—¶é—´ä»ç„¶ > 60 ç§’

å¯èƒ½åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š
- æ•°æ®åº“è¿æ¥æ± å¤ªå° â†’ å¢åŠ åˆ°è‡³å°‘ 20
- æ‰¹æ¬¡å¤§å°å¤ªå° â†’ å¢åŠ åˆ° 10000
- å·¥ä½œçº¿ç¨‹æ•°ä¸è¶³ â†’ å¢åŠ åˆ° CPU æ ¸å¿ƒæ•°
- æ•°æ®åº“é…ç½®æœªä¼˜åŒ– â†’ è°ƒæ•´ MySQL é…ç½®
- CSV è§£ææ…¢ â†’ ä½¿ç”¨æ›´å¿«çš„è§£æåº“

è¯Šæ–­å‘½ä»¤ï¼š
```bash
# æ£€æŸ¥ CPU ä½¿ç”¨ç‡
top -p $(pgrep -f "node.*data-cleaning")

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
ps aux | grep node

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
mysql -e "SHOW PROCESSLIST;"
```

**é—®é¢˜ 2: å†…å­˜æº¢å‡º**

ç—‡çŠ¶ï¼šè¿›ç¨‹å´©æºƒï¼Œé”™è¯¯ "JavaScript heap out of memory"

è§£å†³æ–¹æ¡ˆï¼š
- å‡å°‘æ‰¹æ¬¡å¤§å°
- å‡å°‘å·¥ä½œçº¿ç¨‹æ•°
- ç¡®ä¿ä½¿ç”¨æµå¼è¯»å–
- å¢åŠ  Node.js å †å¤§å°ï¼š`node --max-old-space-size=4096`

**é—®é¢˜ 3: å·¥ä½œçº¿ç¨‹è¶…æ—¶**

ç—‡çŠ¶ï¼šå·¥ä½œçº¿ç¨‹åœ¨ 5 åˆ†é’Ÿåè¢«ç»ˆæ­¢

è§£å†³æ–¹æ¡ˆï¼š
- æ£€æŸ¥æ•°æ®åº“è¿æ¥æ˜¯å¦æ­£å¸¸
- æ£€æŸ¥ CSV æ–‡ä»¶æ˜¯å¦æŸå
- å¢åŠ è¶…æ—¶æ—¶é—´
- æ£€æŸ¥æ˜¯å¦æœ‰æ­»é”

**é—®é¢˜ 4: æ•°æ®ä¸ä¸€è‡´**

ç—‡çŠ¶ï¼šå¹¶è¡Œå¤„ç†ç»“æœä¸é¡ºåºå¤„ç†ä¸åŒ

è§£å†³æ–¹æ¡ˆï¼š
- æ£€æŸ¥å·¥ä½œçº¿ç¨‹æ˜¯å¦å¤„ç†äº†é‡å çš„è¡Œ
- éªŒè¯æ•°æ®å—åˆ†å‰²é€»è¾‘
- æ£€æŸ¥æ•°æ®åº“äº‹åŠ¡æ˜¯å¦æ­£ç¡®
- è¿è¡Œå±æ€§æµ‹è¯•éªŒè¯

**é—®é¢˜ 5: æ•°æ®åº“è¿æ¥è€—å°½**

ç—‡çŠ¶ï¼šé”™è¯¯ "Too many connections"

è§£å†³æ–¹æ¡ˆï¼š
- å¢åŠ æ•°æ®åº“æœ€å¤§è¿æ¥æ•°
- å‡å°‘å·¥ä½œçº¿ç¨‹æ•°
- ç¡®ä¿è¿æ¥æ­£ç¡®é‡Šæ”¾
- ä½¿ç”¨è¿æ¥æ± 


## æœ€ä½³å®è·µ

### 1. ä»£ç ç»„ç»‡

```
src/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ parallel/
â”‚   â”‚   â”œâ”€â”€ parallel-processing-manager.service.ts
â”‚   â”‚   â”œâ”€â”€ worker-pool.service.ts
â”‚   â”‚   â”œâ”€â”€ chunk-splitter.service.ts
â”‚   â”‚   â”œâ”€â”€ result-collector.service.ts
â”‚   â”‚   â”œâ”€â”€ progress-tracker.service.ts
â”‚   â”‚   â”œâ”€â”€ resource-monitor.service.ts
â”‚   â”‚   â””â”€â”€ types.ts
â”‚   â””â”€â”€ data-cleaner.service.ts
â”œâ”€â”€ workers/
â”‚   â””â”€â”€ data-cleaning.worker.ts
â”œâ”€â”€ config/
â”‚   â””â”€â”€ worker-threads.config.ts
â””â”€â”€ tests/
    â”œâ”€â”€ unit/
    â”‚   â”œâ”€â”€ chunk-splitter.spec.ts
    â”‚   â”œâ”€â”€ worker-pool.spec.ts
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ integration/
    â”‚   â””â”€â”€ parallel-processing.spec.ts
    â””â”€â”€ property/
        â””â”€â”€ parallel-processing.property.spec.ts
```

### 2. æ—¥å¿—è®°å½•

```typescript
// ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—
this.logger.log({
  message: 'Parallel processing started',
  jobId,
  workerCount: 4,
  totalRows: 1000000,
  batchSize: 10000
});

this.logger.log({
  message: 'Worker completed',
  workerId: 1,
  successCount: 248000,
  errorCount: 2000,
  processingTimeMs: 12500
});

this.logger.log({
  message: 'Parallel processing completed',
  jobId,
  totalSuccessCount: 995000,
  totalErrorCount: 5000,
  totalProcessingTimeMs: 45000,
  speedup: 3.2
});
```

### 3. ç›‘æ§æŒ‡æ ‡

å…³é”®æŒ‡æ ‡ï¼š
- å¤„ç†æ—¶é—´ï¼ˆç›®æ ‡ï¼š< 60 ç§’ï¼‰
- CPU åˆ©ç”¨ç‡ï¼ˆç›®æ ‡ï¼š> 80%ï¼‰
- å†…å­˜ä½¿ç”¨ï¼ˆç›®æ ‡ï¼š< 2GBï¼‰
- ååé‡ï¼ˆç›®æ ‡ï¼š> 16k è¡Œ/ç§’ï¼‰
- é”™è¯¯ç‡
- å·¥ä½œçº¿ç¨‹å¤±è´¥ç‡

### 4. æ¸è¿›å¼éƒ¨ç½²

1. **é˜¶æ®µ 1ï¼š** åœ¨æµ‹è¯•ç¯å¢ƒå¯ç”¨å¹¶è¡Œå¤„ç†
2. **é˜¶æ®µ 2ï¼š** åœ¨ç”Ÿäº§ç¯å¢ƒå¯¹ 10% æµé‡å¯ç”¨
3. **é˜¶æ®µ 3ï¼š** é€æ­¥å¢åŠ åˆ° 50%
4. **é˜¶æ®µ 4ï¼š** å…¨é‡å¯ç”¨
5. **å›æ»šï¼š** å¦‚æœ‰é—®é¢˜ï¼Œé€šè¿‡é…ç½®ç«‹å³ç¦ç”¨


## é¢„æœŸæ€§èƒ½ç»“æœ

### åŸºå‡†æµ‹è¯•ç»“æœï¼ˆ100 ä¸‡è¡Œï¼‰

| æŒ‡æ ‡ | å½“å‰ï¼ˆé¡ºåºï¼‰ | ç›®æ ‡ï¼ˆå¹¶è¡Œï¼‰ | å®é™…é¢„æœŸ |
|-----|------------|------------|---------|
| å¤„ç†æ—¶é—´ | 150-240 ç§’ | 45-60 ç§’ | 50-55 ç§’ |
| CPU åˆ©ç”¨ç‡ | 25% | 80-100% | 85-95% |
| å†…å­˜ä½¿ç”¨ | 500MB | 1200-1800MB | 1400-1600MB |
| ååé‡ | 4-7k è¡Œ/ç§’ | 16-22k è¡Œ/ç§’ | 18-20k è¡Œ/ç§’ |
| æ•°æ®åº“è¿æ¥ | 2-3 | 8-12 | 10-12 |

### æ€§èƒ½æå‡åˆ†è§£

**æ—¶é—´èŠ‚çœæ¥æºï¼š**
1. **å¹¶è¡Œå¤„ç†ï¼š** 4 ä¸ªå·¥ä½œçº¿ç¨‹åŒæ—¶å¤„ç† â†’ èŠ‚çœ 60-70%
2. **æ‰¹é‡æ’å…¥ä¼˜åŒ–ï¼š** 10000 è¡Œ/æ‰¹ â†’ èŠ‚çœ 10-15%
3. **åŸç”Ÿ SQLï¼š** æ›¿ä»£ ORM â†’ èŠ‚çœ 5-10%
4. **é¢„ç¼–è¯‘æ­£åˆ™ï¼š** é¿å…é‡å¤ç¼–è¯‘ â†’ èŠ‚çœ 3-5%

**æ€»è®¡ï¼š** çº¦ 250-300% æ€§èƒ½æå‡

### ä¸åŒæ–‡ä»¶å¤§å°çš„é¢„æœŸæ€§èƒ½

| æ–‡ä»¶å¤§å° | é¡ºåºå¤„ç† | å¹¶è¡Œå¤„ç† | åŠ é€Ÿæ¯” |
|---------|---------|---------|--------|
| 1,000 è¡Œ | 0.5 ç§’ | 0.5 ç§’ | 1.0xï¼ˆä¸å¯ç”¨å¹¶è¡Œï¼‰|
| 10,000 è¡Œ | 5 ç§’ | 3 ç§’ | 1.7x |
| 100,000 è¡Œ | 50 ç§’ | 20 ç§’ | 2.5x |
| 1,000,000 è¡Œ | 200 ç§’ | 55 ç§’ | 3.6x |
| 5,000,000 è¡Œ | 1000 ç§’ | 280 ç§’ | 3.6x |

## æ€»ç»“

æœ¬å®æ–½æŒ‡å—æä¾›äº† Worker Threads å¹¶è¡Œå¤„ç†ä¼˜åŒ–çš„è¯¦ç»†å®ç°æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

1. **æ ¸å¿ƒæ¶æ„ï¼š** ä¸»çº¿ç¨‹åè°ƒ + 4 ä¸ªå·¥ä½œçº¿ç¨‹å¹¶è¡Œå¤„ç†
2. **å…³é”®ä¼˜åŒ–ï¼š** CSV æµå¼è¯»å–ã€æ‰¹é‡æ•°æ®åº“æ’å…¥ã€é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
3. **é”™è¯¯å¤„ç†ï¼š** å¤šå±‚é”™è¯¯å¤„ç†ã€è¶…æ—¶æœºåˆ¶ã€éƒ¨åˆ†ç»“æœæ”¶é›†
4. **æµ‹è¯•ç­–ç•¥ï¼š** å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€å±æ€§æµ‹è¯•ã€æ€§èƒ½æµ‹è¯•
5. **éƒ¨ç½²æ–¹æ¡ˆï¼š** æ¸è¿›å¼éƒ¨ç½²ã€ç›‘æ§æŒ‡æ ‡ã€æ•…éšœæ’é™¤

é€šè¿‡éµå¾ªæœ¬æŒ‡å—ï¼Œé¢„æœŸå¯ä»¥å°† 100 ä¸‡è¡Œæ•°æ®çš„å¤„ç†æ—¶é—´ä» 150-240 ç§’é™ä½åˆ° 45-60 ç§’ï¼Œå®ç° 250% ä»¥ä¸Šçš„æ€§èƒ½æå‡ï¼ŒåŒæ—¶ä¿æŒ 100% çš„æ•°æ®å®Œæ•´æ€§å’Œå‡†ç¡®æ€§ã€‚

## ä¸‹ä¸€æ­¥

1. é˜…è¯» `requirements.md` äº†è§£è¯¦ç»†éœ€æ±‚
2. é˜…è¯» `design.md` äº†è§£ç³»ç»Ÿè®¾è®¡
3. æŒ‰ç…§ `tasks.md` ä¸­çš„ä»»åŠ¡åˆ—è¡¨é€æ­¥å®æ–½
4. å‚è€ƒæœ¬æŒ‡å—ä¸­çš„ä»£ç ç¤ºä¾‹å’Œä¼˜åŒ–å»ºè®®
5. è¿è¡Œæµ‹è¯•éªŒè¯å®ç°
6. è¿›è¡Œæ€§èƒ½æµ‹è¯•ç¡®ä¿è¾¾åˆ°ç›®æ ‡
7. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒå¹¶ç›‘æ§

ç¥å®æ–½é¡ºåˆ©ï¼ğŸš€

## æ€§èƒ½ç›‘æ§å®ç°

### 1. PerformanceMonitor å®ç°ç¤ºä¾‹

```typescript
// src/services/parallel/performance-monitor.service.ts
import { Injectable, Logger } from '@nestjs/common';
import * as os from 'os';

@Injectable()
export class PerformanceMonitor {
  private readonly logger = new Logger(PerformanceMonitor.name);
  
  private jobId: string;
  private startTime: number;
  private monitoringInterval: NodeJS.Timeout;
  private snapshots: PerformanceSnapshot[] = [];
  private workerMetricsMap: Map<number, WorkerMetrics[]> = new Map();
  
  // åŸºå‡† CPU ä½¿ç”¨ï¼ˆç”¨äºè®¡ç®—å¢é‡ï¼‰
  private baselineCpuUsage: NodeJS.CpuUsage;
  
  /**
   * å¼€å§‹æ€§èƒ½ç›‘æ§
   */
  startMonitoring(jobId: string): void {
    this.jobId = jobId;
    this.startTime = Date.now();
    this.snapshots = [];
    this.workerMetricsMap.clear();
    
    // è®°å½•åŸºå‡† CPU ä½¿ç”¨
    this.baselineCpuUsage = process.cpuUsage();
    
    // æ¯ç§’é‡‡æ ·ä¸€æ¬¡
    this.monitoringInterval = setInterval(() => {
      this.collectSnapshot();
    }, 1000);
    
    this.logger.log(`Performance monitoring started for job ${jobId}`);
  }
  
  /**
   * åœæ­¢æ€§èƒ½ç›‘æ§å¹¶ç”ŸæˆæŠ¥å‘Š
   */
  stopMonitoring(): PerformanceReport {
    if (this.monitoringInterval) {
      clearInterval(this.monitoringInterval);
    }
    
    const duration = Date.now() - this.startTime;
    const report = this.generateReport(duration);
    
    this.logger.log(`Performance monitoring stopped for job ${this.jobId}`);
    this.logger.log(`Report: ${JSON.stringify(report, null, 2)}`);
    
    return report;
  }
  
  /**
   * è·å–å½“å‰æ€§èƒ½æŒ‡æ ‡
   */
  getCurrentMetrics(): PerformanceMetrics {
    const cpuMetrics = this.getCPUMetrics();
    const memoryMetrics = this.getMemoryMetrics();
    const workerMetrics = this.getLatestWorkerMetrics();
    const throughput = this.calculateCurrentThroughput();
    
    return {
      timestamp: Date.now(),
      cpuUsage: cpuMetrics,
      memoryUsage: memoryMetrics,
      workerMetrics,
      throughput,
    };
  }
  
  /**
   * è®°å½•å·¥ä½œçº¿ç¨‹æŒ‡æ ‡
   */
  recordWorkerMetrics(workerId: number, metrics: WorkerMetrics): void {
    if (!this.workerMetricsMap.has(workerId)) {
      this.workerMetricsMap.set(workerId, []);
    }
    
    this.workerMetricsMap.get(workerId).push({
      ...metrics,
      timestamp: Date.now(),
    });
  }
  
  /**
   * æ”¶é›†æ€§èƒ½å¿«ç…§
   */
  private collectSnapshot(): void {
    const metrics = this.getCurrentMetrics();
    
    this.snapshots.push({
      timestamp: metrics.timestamp,
      cpuUsage: metrics.cpuUsage.overall,
      memoryUsage: metrics.memoryUsage.heapUsedMB,
      processedRows: this.getTotalProcessedRows(),
      throughput: metrics.throughput,
    });
  }
  
  /**
   * è·å– CPU æŒ‡æ ‡
   */
  private getCPUMetrics(): CPUMetrics {
    const cpus = os.cpus();
    const cpuUsage = process.cpuUsage(this.baselineCpuUsage);
    
    // è®¡ç®—æ€» CPU æ—¶é—´ï¼ˆå¾®ç§’ï¼‰
    const totalCpuTime = cpuUsage.user + cpuUsage.system;
    
    // è®¡ç®—ç»è¿‡çš„æ—¶é—´ï¼ˆå¾®ç§’ï¼‰
    const elapsedTime = (Date.now() - this.startTime) * 1000;
    
    // è®¡ç®— CPU ä½¿ç”¨ç‡ç™¾åˆ†æ¯”
    const cpuCount = cpus.length;
    const overall = Math.min(100, (totalCpuTime / elapsedTime) * 100);
    
    // è®¡ç®—æ¯ä¸ªæ ¸å¿ƒçš„ä½¿ç”¨ç‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
    const perCore = cpus.map((cpu, index) => {
      const total = Object.values(cpu.times).reduce((a, b) => a + b, 0);
      const idle = cpu.times.idle;
      return ((total - idle) / total) * 100;
    });
    
    return {
      overall,
      perCore,
      user: (cpuUsage.user / elapsedTime) * 100,
      system: (cpuUsage.system / elapsedTime) * 100,
    };
  }
  
  /**
   * è·å–å†…å­˜æŒ‡æ ‡
   */
  private getMemoryMetrics(): MemoryMetrics {
    const memUsage = process.memoryUsage();
    const totalMemory = os.totalmem();
    
    const heapUsedMB = memUsage.heapUsed / 1024 / 1024;
    const heapTotalMB = memUsage.heapTotal / 1024 / 1024;
    const rssMB = memUsage.rss / 1024 / 1024;
    const usagePercentage = (memUsage.rss / totalMemory) * 100;
    
    return {
      heapUsed: memUsage.heapUsed,
      heapTotal: memUsage.heapTotal,
      external: memUsage.external,
      rss: memUsage.rss,
      heapUsedMB,
      heapTotalMB,
      rssMB,
      usagePercentage,
    };
  }
  
  /**
   * è·å–æœ€æ–°çš„å·¥ä½œçº¿ç¨‹æŒ‡æ ‡
   */
  private getLatestWorkerMetrics(): WorkerMetrics[] {
    const latestMetrics: WorkerMetrics[] = [];
    
    this.workerMetricsMap.forEach((metrics, workerId) => {
      if (metrics.length > 0) {
        latestMetrics.push(metrics[metrics.length - 1]);
      }
    });
    
    return latestMetrics;
  }
  
  /**
   * è®¡ç®—å½“å‰ååé‡
   */
  private calculateCurrentThroughput(): number {
    const totalProcessed = this.getTotalProcessedRows();
    const elapsedSeconds = (Date.now() - this.startTime) / 1000;
    
    return elapsedSeconds > 0 ? totalProcessed / elapsedSeconds : 0;
  }
  
  /**
   * è·å–æ€»å¤„ç†è¡Œæ•°
   */
  private getTotalProcessedRows(): number {
    let total = 0;
    
    this.workerMetricsMap.forEach((metrics) => {
      if (metrics.length > 0) {
        const latest = metrics[metrics.length - 1];
        total += latest.processedRows;
      }
    });
    
    return total;
  }
  
  /**
   * ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
   */
  private generateReport(duration: number): PerformanceReport {
    // è®¡ç®— CPU æŒ‡æ ‡
    const cpuSnapshots = this.snapshots.map(s => s.cpuUsage);
    const avgCpuUsage = this.average(cpuSnapshots);
    const peakCpuUsage = Math.max(...cpuSnapshots);
    const cpuUtilization = (avgCpuUsage / (os.cpus().length * 100)) * 100;
    
    // è®¡ç®—å†…å­˜æŒ‡æ ‡
    const memorySnapshots = this.snapshots.map(s => s.memoryUsage);
    const avgMemoryUsage = this.average(memorySnapshots);
    const peakMemoryUsage = Math.max(...memorySnapshots);
    const memoryUtilization = (peakMemoryUsage / (os.totalmem() / 1024 / 1024)) * 100;
    
    // è®¡ç®—ååé‡æŒ‡æ ‡
    const throughputSnapshots = this.snapshots.map(s => s.throughput);
    const avgThroughput = this.average(throughputSnapshots);
    const peakThroughput = Math.max(...throughputSnapshots);
    const totalRows = this.getTotalProcessedRows();
    
    // ç”Ÿæˆå·¥ä½œçº¿ç¨‹æŠ¥å‘Š
    const workerReports = this.generateWorkerReports();
    
    return {
      jobId: this.jobId,
      duration,
      avgCpuUsage,
      peakCpuUsage,
      cpuUtilization,
      avgMemoryUsage,
      peakMemoryUsage,
      memoryUtilization,
      totalRows,
      avgThroughput,
      peakThroughput,
      workerReports,
      timeline: this.snapshots,
    };
  }
  
  /**
   * ç”Ÿæˆå·¥ä½œçº¿ç¨‹æŠ¥å‘Š
   */
  private generateWorkerReports(): WorkerReport[] {
    const reports: WorkerReport[] = [];
    
    this.workerMetricsMap.forEach((metrics, workerId) => {
      if (metrics.length === 0) return;
      
      const cpuValues = metrics.map(m => m.cpuUsage);
      const memoryValues = metrics.map(m => m.memoryUsage);
      const throughputValues = metrics.map(m => m.throughput);
      
      const firstMetric = metrics[0];
      const lastMetric = metrics[metrics.length - 1];
      const duration = lastMetric.timestamp - firstMetric.timestamp;
      
      reports.push({
        workerId,
        avgCpuUsage: this.average(cpuValues),
        peakCpuUsage: Math.max(...cpuValues),
        avgMemoryUsage: this.average(memoryValues),
        peakMemoryUsage: Math.max(...memoryValues),
        processedRows: lastMetric.processedRows,
        avgThroughput: this.average(throughputValues),
        duration,
      });
    });
    
    return reports;
  }
  
  /**
   * è®¡ç®—å¹³å‡å€¼
   */
  private average(values: number[]): number {
    if (values.length === 0) return 0;
    return values.reduce((a, b) => a + b, 0) / values.length;
  }
}
```

### 2. åœ¨ Worker ä¸­æ”¶é›†æŒ‡æ ‡

```typescript
// src/workers/data-cleaning.worker.ts
import { parentPort } from 'worker_threads';
import * as os from 'os';

let baselineCpuUsage: NodeJS.CpuUsage;
let processedRows = 0;

// åˆå§‹åŒ–
baselineCpuUsage = process.cpuUsage();

// å®šæœŸå‘é€æ€§èƒ½æŒ‡æ ‡
setInterval(() => {
  const cpuUsage = process.cpuUsage(baselineCpuUsage);
  const memUsage = process.memoryUsage();
  
  // è®¡ç®— CPU ä½¿ç”¨ç‡
  const totalCpuTime = cpuUsage.user + cpuUsage.system;
  const elapsedTime = 1000000; // 1 ç§’ï¼ˆå¾®ç§’ï¼‰
  const cpuPercentage = (totalCpuTime / elapsedTime) * 100;
  
  // å‘é€æŒ‡æ ‡åˆ°ä¸»çº¿ç¨‹
  parentPort.postMessage({
    type: 'METRICS',
    payload: {
      workerId: workerData.workerId,
      cpuUsage: cpuPercentage,
      memoryUsage: memUsage.heapUsed / 1024 / 1024, // MB
      processedRows,
      throughput: processedRows / ((Date.now() - startTime) / 1000),
      status: 'running',
    }
  });
}, 1000);

// åœ¨å¤„ç†è®°å½•æ—¶æ›´æ–°è®¡æ•°
function processRecord(record: any) {
  // ... å¤„ç†é€»è¾‘
  processedRows++;
}
```

### 3. API ç«¯ç‚¹å®ç°

```typescript
// src/data-cleaning.controller.ts
import { Controller, Get, Param } from '@nestjs/common';

@Controller('api/data-cleaning')
export class DataCleaningController {
  constructor(
    private readonly parallelProcessingManager: ParallelProcessingManager,
    private readonly performanceMonitor: PerformanceMonitor,
  ) {}
  
  /**
   * è·å–å®æ—¶æ€§èƒ½æŒ‡æ ‡
   */
  @Get('metrics/:jobId')
  async getMetrics(@Param('jobId') jobId: string) {
    const metrics = this.performanceMonitor.getCurrentMetrics();
    
    return {
      jobId,
      timestamp: new Date().toISOString(),
      metrics: {
        cpu: {
          overall: `${metrics.cpuUsage.overall.toFixed(2)}%`,
          perCore: metrics.cpuUsage.perCore.map(c => `${c.toFixed(2)}%`),
          user: `${metrics.cpuUsage.user.toFixed(2)}%`,
          system: `${metrics.cpuUsage.system.toFixed(2)}%`,
        },
        memory: {
          heapUsed: `${metrics.memoryUsage.heapUsedMB.toFixed(2)} MB`,
          heapTotal: `${metrics.memoryUsage.heapTotalMB.toFixed(2)} MB`,
          rss: `${metrics.memoryUsage.rssMB.toFixed(2)} MB`,
          usage: `${metrics.memoryUsage.usagePercentage.toFixed(2)}%`,
        },
        throughput: `${metrics.throughput.toFixed(0)} rows/sec`,
        workers: metrics.workerMetrics.map(w => ({
          id: w.workerId,
          cpu: `${w.cpuUsage.toFixed(2)}%`,
          memory: `${w.memoryUsage.toFixed(2)} MB`,
          processed: w.processedRows,
          throughput: `${w.throughput.toFixed(0)} rows/sec`,
          status: w.status,
        })),
      },
    };
  }
  
  /**
   * è·å–æ€§èƒ½æŠ¥å‘Š
   */
  @Get('report/:jobId')
  async getReport(@Param('jobId') jobId: string) {
    const report = await this.getPerformanceReport(jobId);
    
    return {
      jobId,
      summary: {
        duration: `${(report.duration / 1000).toFixed(2)}s`,
        totalRows: report.totalRows.toLocaleString(),
        avgThroughput: `${report.avgThroughput.toFixed(0)} rows/sec`,
        peakThroughput: `${report.peakThroughput.toFixed(0)} rows/sec`,
      },
      cpu: {
        average: `${report.avgCpuUsage.toFixed(2)}%`,
        peak: `${report.peakCpuUsage.toFixed(2)}%`,
        utilization: `${report.cpuUtilization.toFixed(2)}%`,
      },
      memory: {
        average: `${report.avgMemoryUsage.toFixed(2)} MB`,
        peak: `${report.peakMemoryUsage.toFixed(2)} MB`,
        utilization: `${report.memoryUtilization.toFixed(2)}%`,
      },
      workers: report.workerReports.map(w => ({
        id: w.workerId,
        processed: w.processedRows.toLocaleString(),
        avgCpu: `${w.avgCpuUsage.toFixed(2)}%`,
        peakCpu: `${w.peakCpuUsage.toFixed(2)}%`,
        avgMemory: `${w.avgMemoryUsage.toFixed(2)} MB`,
        peakMemory: `${w.peakMemoryUsage.toFixed(2)} MB`,
        avgThroughput: `${w.avgThroughput.toFixed(0)} rows/sec`,
        duration: `${(w.duration / 1000).toFixed(2)}s`,
      })),
      timeline: report.timeline,
    };
  }
}
```

### 4. å‰ç«¯æ€§èƒ½ä»ªè¡¨æ¿ç¤ºä¾‹

```typescript
// å‰ç«¯å®æ—¶æ€§èƒ½ç›‘æ§ç»„ä»¶
import React, { useEffect, useState } from 'react';
import { Line } from 'react-chartjs-2';

export const PerformanceMonitor: React.FC<{ jobId: string }> = ({ jobId }) => {
  const [metrics, setMetrics] = useState(null);
  
  useEffect(() => {
    const interval = setInterval(async () => {
      const response = await fetch(`/api/data-cleaning/metrics/${jobId}`);
      const data = await response.json();
      setMetrics(data.metrics);
    }, 1000);
    
    return () => clearInterval(interval);
  }, [jobId]);
  
  if (!metrics) return <div>Loading...</div>;
  
  return (
    <div className="performance-monitor">
      <h2>å®æ—¶æ€§èƒ½ç›‘æ§</h2>
      
      <div className="metrics-grid">
        <div className="metric-card">
          <h3>CPU ä½¿ç”¨ç‡</h3>
          <div className="metric-value">{metrics.cpu.overall}</div>
          <div className="metric-detail">
            ç”¨æˆ·æ€: {metrics.cpu.user} | ç³»ç»Ÿæ€: {metrics.cpu.system}
          </div>
        </div>
        
        <div className="metric-card">
          <h3>å†…å­˜ä½¿ç”¨</h3>
          <div className="metric-value">{metrics.memory.heapUsed}</div>
          <div className="metric-detail">
            æ€»è®¡: {metrics.memory.heapTotal} | ä½¿ç”¨ç‡: {metrics.memory.usage}
          </div>
        </div>
        
        <div className="metric-card">
          <h3>ååé‡</h3>
          <div className="metric-value">{metrics.throughput}</div>
        </div>
      </div>
      
      <div className="workers-section">
        <h3>å·¥ä½œçº¿ç¨‹çŠ¶æ€</h3>
        <table>
          <thead>
            <tr>
              <th>ID</th>
              <th>çŠ¶æ€</th>
              <th>CPU</th>
              <th>å†…å­˜</th>
              <th>å·²å¤„ç†</th>
              <th>ååé‡</th>
            </tr>
          </thead>
          <tbody>
            {metrics.workers.map(worker => (
              <tr key={worker.id}>
                <td>{worker.id}</td>
                <td>{worker.status}</td>
                <td>{worker.cpu}</td>
                <td>{worker.memory}</td>
                <td>{worker.processed.toLocaleString()}</td>
                <td>{worker.throughput}</td>
              </tr>
            ))}
          </tbody>
        </table>
      </div>
    </div>
  );
};
```

è¿™ä¸ªæ€§èƒ½ç›‘æ§å®ç°æä¾›äº†ï¼š
- å®æ—¶ CPU ä½¿ç”¨ç‡ç›‘æ§ï¼ˆæ€»ä½“å’Œæ¯æ ¸å¿ƒï¼‰
- å®æ—¶å†…å­˜ä½¿ç”¨ç›‘æ§ï¼ˆå †å†…å­˜ã€RSSã€ä½¿ç”¨ç™¾åˆ†æ¯”ï¼‰
- å®æ—¶ååé‡è®¡ç®—
- æ¯ä¸ªå·¥ä½œçº¿ç¨‹çš„ç‹¬ç«‹æŒ‡æ ‡
- å®Œæ•´çš„æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
- æ—¶é—´çº¿æ•°æ®ç”¨äºå›¾è¡¨å±•ç¤º
- RESTful API ç«¯ç‚¹
- å‰ç«¯å®æ—¶ç›‘æ§ç»„ä»¶
